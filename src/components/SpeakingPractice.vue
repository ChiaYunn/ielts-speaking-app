<template>
  <div class="p-4 max-w-3xl mx-auto">
    <h1 class="text-2xl font-bold mb-4">è‹±èªå£èªªç·´ç¿’</h1>
    <button @click="loadRandomArticle" class="btn mb-4">ğŸ”„ change news</button>

    <div class="mb-4">
      <!-- ç”¨ v-html é¡¯ç¤ºåŠ äº† mark çš„æ–‡å­— -->
      <p class="text-gray-700 whitespace-pre-wrap" v-html="highlightedText"></p>
    </div>

    <div class="mb-4 flex flex-wrap gap-2">
      <button @click="speakText" class="btn">ğŸ” Play</button>
      <button @click="pauseSpeech" class="btn">â¸ï¸ Pause</button>
      <button @click="resumeSpeech" class="btn">â–¶ï¸ Resume</button>
      <button @click="startRecording" class="btn" :disabled="isRecording">ğŸ™ï¸ Start</button>
      <button @click="stopRecording" class="btn" :disabled="!isRecording">ğŸ›‘ Stop</button>
    </div>
    
    <div class="mb-2">Play progressï¼š{{ playProgress }}%</div>
    <div class="mb-2">Time spentï¼š{{ timer }} ç§’</div>
    <div class="mb-4">Correct rateï¼š{{ accuracy }}%</div>

    <div class="mt-4">
      <h2 class="font-semibold">The text you read out (including intermediate results):</h2>
      <p class="text-sm text-gray-600 whitespace-pre-wrap">{{ transcript }}</p>
    </div>
  </div>
</template>

<script setup>
import { ref, onMounted } from 'vue'

const articles = ref([])
const originalText = ref('Loading article...')
const highlightedText = ref('')
const transcript = ref('')
const spokenText = ref('')
const accuracy = ref(0)
const timer = ref(0)
const isRecording = ref(false)

let utterance = null
let intervalId = null
let recognition = null
let finalTranscript = ''

// æ’­æ”¾é€²åº¦ç™¾åˆ†æ¯”
const playProgress = ref(0)
// ç›®å‰å”¸åˆ°çš„å–®å­—ç´¢å¼•
const currentWordIndex = ref(-1)

// è¼‰å…¥æ–‡ç«  JSON
onMounted(async () => {
  try {
    const res = await fetch('/cnn_articles.json')
    const data = await res.json()
    articles.value = data

    if (data.length > 0 && data[0].content) {
      originalText.value = data[0].content.trim()
      highlightedText.value = originalText.value
    } else {
      originalText.value = 'âš ï¸ æ‰¾ä¸åˆ°æ–‡ç« å…§å®¹'
      highlightedText.value = originalText.value
    }
  } catch (err) {
    console.error('âŒ ç„¡æ³•è®€å– cnn_articles.json:', err)
    originalText.value = 'âŒ ç„¡æ³•è¼‰å…¥æ–‡ç« '
    highlightedText.value = originalText.value
  }
})

// æ›´æ–°é«˜äº®æ–‡å­—ï¼Œå°‡ç›®å‰å­—ç”¨ <mark> åŒ…èµ·ä¾†
function updateHighlightedText() {
  const words = originalText.value.trim().split(/\s+/)
  highlightedText.value = words
    .map((word, i) => i === currentWordIndex.value ? `<mark>${word}</mark>` : word)
    .join(' ')
}

const speakText = () => {
  // å¦‚æœæ­£åœ¨æ’­æ”¾æˆ–æš«åœï¼Œå…ˆå–æ¶ˆ
  if (speechSynthesis.speaking || speechSynthesis.paused) {
    speechSynthesis.cancel()
  }

  utterance = new SpeechSynthesisUtterance(originalText.value)
  utterance.lang = 'en-US'

  utterance.onstart = () => {
    currentWordIndex.value = -1
    playProgress.value = 0
    updateHighlightedText()
  }

  utterance.onend = () => {
    currentWordIndex.value = -1
    playProgress.value = 100
    updateHighlightedText()
    console.log('ğŸ”š æ’­æ”¾å®Œç•¢')
  }

  // ç•¶æ¯å€‹å–®å­—é–‹å§‹å”¸æ™‚æ›´æ–°é«˜äº®åŠé€²åº¦
  utterance.onboundary = (event) => {
    if (event.name === 'word') {
      const textBefore = originalText.value.slice(0, event.charIndex)
      const wordIndex = textBefore.trim().split(/\s+/).length - 1
      currentWordIndex.value = wordIndex >= 0 ? wordIndex : 0
      updateHighlightedText()

      const totalWords = originalText.value.trim().split(/\s+/).length
      playProgress.value = Math.min(100, Math.round(((wordIndex + 1) / totalWords) * 100))
    }
  }

  speechSynthesis.speak(utterance)
  console.log('ğŸ”Š é–‹å§‹æ’­æ”¾')
}

const pauseSpeech = () => {
  if (speechSynthesis.speaking && !speechSynthesis.paused) {
    speechSynthesis.pause()
    console.log('â¸ï¸ æš«åœæ’­æ”¾')
  } else {
    console.log('âš ï¸ ç„¡æ³•æš«åœï¼šå°šæœªæ’­æ”¾æˆ–å·²æš«åœ')
  }
}

const resumeSpeech = () => {
  if (speechSynthesis.paused) {
    speechSynthesis.resume()
    console.log('â–¶ï¸ ç¹¼çºŒæ’­æ”¾')
  } else {
    console.log('âš ï¸ ç„¡æ³•ç¹¼çºŒï¼šæœªè™•æ–¼æš«åœç‹€æ…‹')
  }
}


// è©•ä¼°å£èªªæ­£ç¢ºç‡
const evaluateAccuracy = () => {
  const clean = (str) => str.toLowerCase().replace(/[.,]/g, '')
  const originalWords = clean(originalText.value).split(/\s+/)
  const spokenWords = clean(spokenText.value).split(/\s+/)

  let correct = 0
  const highlighted = originalWords.map((word, i) => {
    if (spokenWords[i] === word) {
      correct++
      return word
    } else {
      return `<span style='color:red'>${word}</span>`
    }
  })

  accuracy.value = Math.round((correct / originalWords.length) * 100)
  highlightedText.value = highlighted.join(' ')
}

// é–‹å§‹éŒ„éŸ³
const startRecording = () => {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
  if (!SpeechRecognition) {
    alert('âŒ ä¸æ”¯æ´ Web Speech APIï¼Œè«‹ä½¿ç”¨ Chrome ç€è¦½å™¨ã€‚')
    return
  }

  transcript.value = ''
  spokenText.value = ''
  finalTranscript = ''
  isRecording.value = true
  timer.value = 0
  intervalId = setInterval(() => timer.value++, 1000)

  recognition = new SpeechRecognition()
  recognition.lang = 'en-US'
  recognition.continuous = true
  recognition.interimResults = true

  recognition.onstart = () => console.log('ğŸ¤ é–‹å§‹éŒ„éŸ³')
  recognition.onerror = (e) => console.error('âŒ éŒ¯èª¤ï¼š', e.error)

  recognition.onresult = (event) => {
    let interimTranscript = ''
    for (let i = event.resultIndex; i < event.results.length; i++) {
      if (event.results[i].isFinal) {
        finalTranscript += event.results[i][0].transcript + ' '
      } else {
        interimTranscript += event.results[i][0].transcript
      }
    }

    transcript.value = finalTranscript + interimTranscript
    spokenText.value = transcript.value.toLowerCase()
    evaluateAccuracy()
  }

  recognition.onend = () => {
    console.log('ğŸ›‘ éŒ„éŸ³çµæŸ')
    stopRecording()
  }

  recognition.start()
}

// åœæ­¢éŒ„éŸ³
const stopRecording = () => {
  if (!isRecording.value) return

  isRecording.value = false
  clearInterval(intervalId)

  try {
    recognition.stop()
  } catch (e) {
    console.warn('ğŸ¤ åœæ­¢éŒ„éŸ³éŒ¯èª¤:', e)
  }

  if (!transcript.value && spokenText.value) {
    transcript.value = spokenText.value
    evaluateAccuracy()
  }

  setTimeout(() => {
    if (!transcript.value) {
      alert('â— æ²’æœ‰åµæ¸¬åˆ°èªéŸ³ï¼Œè«‹ç¢ºèªéº¥å…‹é¢¨æ­£å¸¸ä¸¦å†è©¦ä¸€æ¬¡ã€‚')
    }
  }, 500)
}

const loadRandomArticle = () => {
  if (articles.value.length === 0) return

  const randomIndex = Math.floor(Math.random() * articles.value.length)
  const newArticle = articles.value[randomIndex]?.content?.trim()

  if (newArticle) {
    originalText.value = newArticle
    highlightedText.value = newArticle
    transcript.value = ''
    spokenText.value = ''
    accuracy.value = 0
  } else {
    originalText.value = 'âš ï¸ ç„¡æ³•è¼‰å…¥æ–°æ–‡ç« '
    highlightedText.value = originalText.value
  }

  // åœæ­¢ä»»ä½•æ­£åœ¨æ’­æ”¾çš„èªéŸ³
  speechSynthesis.cancel()
}


</script>

<style>
.btn {
  background-color: #299e5e;
  color: white;
  padding: 0.5rem 1rem;
  border-radius: 0.5rem;
  transition: background-color 0.3s;
  cursor: pointer;
  user-select: none;
}
.btn:hover:not(:disabled) {
  background-color: #247d4e;
}
.btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.btn + .btn {
  margin-left: 0.5rem;
}
</style>
